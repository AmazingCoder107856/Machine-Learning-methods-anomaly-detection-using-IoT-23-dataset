{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da21591-6c8e-486f-ad05-5fb4b1d1f028",
   "metadata": {},
   "source": [
    "# Supervised ML and DL methods for anomaly detection in IOT to enahnce network security\n",
    "## Part 4 - DATA TUNING - ADABOOST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6226d3dc-dc98-4252-b452-51d2642c630a",
   "metadata": {},
   "source": [
    "The IoT-23 dataset is a collection of network traffic from Internet of Things (IoT) devices. It includes 20 malware captures executed in IoT devices, and 3 hotspot captures for benign IoT devices traffic12. The 3 hotspot captures are not being included in the data cleaning because this feature was not considered relevant for the specific analysis being performed.\n",
    "\n",
    "In this notebook, we load the processed dataset file and use it to tune one of the previously trained classification models.\n",
    "\n",
    "> **INPUT:** the cleaned and processed dataset csv file. <br>\n",
    "> **OUTPUT:** an analysis of the model's performance before/after tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee918b10-7a8c-46bd-be14-302474f7b611",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0d644b-ec0d-4566-86fd-eb22c1e8b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, precision_score, confusion_matrix, recall_score, accuracy_score, f1_score\n",
    "from statistics import mean\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093b20e3-9957-46a6-a580-9354cdd7535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.float\", \"{:.2f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67eca1c8-a47e-48af-9a5d-ebcedd3c4551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "data_df = pd.read_csv('../CSV-data/processed/iot23_processed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c195875b-717b-4786-a618-faea566adf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into independent and dependent variables\n",
    "data_X = data_df.drop(\"label\", axis=1)\n",
    "data_y = data_df[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a08b08-fb49-4bb4-bacc-a041a2e10152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform or normalize our data with standard scalar function\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe61b9c1-058d-4ac8-a5b8-5114718ba226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86153ba7-fd9a-4194-a36a-003dbfe2057b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0: 158360 samples\n",
      "Class 1.0: 158360 samples\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = AdaBoostClassifier(algorithm='SAMME')\n",
    "\n",
    "# Define the oversampler and undersampler\n",
    "oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "# Apply oversampling\n",
    "X_over, y_over = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Apply undersampling\n",
    "X_under, y_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# Count the number of instances in each class\n",
    "counter = Counter(y_over)\n",
    "counter = Counter(y_under)\n",
    "\n",
    "# Print the number of instances in each class\n",
    "# the number of instances in the minority class should be equal to the number of instances in the majority class.\n",
    "for class_label, num_samples in counter.items():\n",
    "    print(f'Class {class_label}: {num_samples} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6071d7c6-209a-4c91-91ab-7283b1ec234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X, data_y = make_classification(n_samples=158360, random_state=1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.2, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d4a569-b382-4a72-8deb-7e766d589012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'algorithm': 'SAMME', 'learning_rate': 0.1, 'n_estimators': 150}\n",
      "time cost:  831.6050457954407 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Define the model\n",
    "model = AdaBoostClassifier(algorithm='SAMME')\n",
    "\n",
    "# Define the parameter grid\n",
    "parameters = {'n_estimators': [50, 100, 150, 200],\n",
    "    'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "    'algorithm': ['SAMME']}\n",
    "\n",
    "# Initialize cross validation method\n",
    "cross_validation_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1000)\n",
    "\n",
    "# Initialize tuning process\n",
    "grid = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=parameters, \n",
    "    scoring=['accuracy','recall','precision','f1'],\n",
    "    cv=cross_validation_folds,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit='accuracy')\n",
    "\n",
    "# Train the model\n",
    "grid.fit(data_X, data_y)\n",
    "best_params = grid.best_params_\n",
    "\n",
    "print (\"Best Parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "end = time.time()\n",
    "print('time cost: ',end - start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75d19653-55f6-4d23-aeab-ae388b1edfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 99.45%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                 0        1  accuracy  macro avg  weighted avg\n",
      "precision     1.00     0.99      0.99       0.99          0.99\n",
      "recall        0.99     1.00      0.99       0.99          0.99\n",
      "f1-score      0.99     0.99      0.99       0.99          0.99\n",
      "support   63442.00 63246.00      0.99  126688.00     126688.00\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[63059   383]\n",
      " [  309 62937]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.46%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                 0        1  accuracy  macro avg  weighted avg\n",
      "precision     0.99     1.00      0.99       0.99          0.99\n",
      "recall        0.99     0.99      0.99       0.99          0.99\n",
      "f1-score      0.99     0.99      0.99       0.99          0.99\n",
      "support   15768.00 15904.00      0.99   31672.00      31672.00\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[15689    79]\n",
      " [   93 15811]]\n",
      "\n",
      "time cost:  57.31307125091553 seconds\n"
     ]
    }
   ],
   "source": [
    "start1 = time.time()\n",
    "\n",
    "ab_clf = AdaBoostClassifier(**best_params)\n",
    "\n",
    "# Initialize the results for each classifier\n",
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "f1_scores = []\n",
    "best_f1 = -1\n",
    "best_model = None\n",
    "\n",
    "# Train the classifier\n",
    "ab_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test samples\n",
    "y_pred = ab_clf.predict(X_test)\n",
    "\n",
    "# Calculate and register accuracy metrics\n",
    "accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "recall_scores.append(recall_score(y_test, y_pred))\n",
    "precision_scores.append(precision_score(y_test, y_pred))\n",
    "est_f1_score = f1_score(y_test, y_pred)\n",
    "f1_scores.append(est_f1_score)\n",
    "\n",
    "# Compare with best performing model\n",
    "if best_f1 < est_f1_score:\n",
    "    best_model = ab_clf\n",
    "    best_f1 = est_f1_score\n",
    "\n",
    "print_score(ab_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(ab_clf, X_train, y_train, X_test, y_test, train=False)\n",
    "\n",
    "end1 = time.time()\n",
    "print('time cost: ',end1 - start1, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "183e5a71-f48b-4059-84fd-fe6747b881d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time(in sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AB Base</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>196.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AB Tuned</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>831.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AB Trained</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>57.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy Recall Precision   F1 Time(in sec)\n",
       "AB Base        0.94   0.96      0.97 0.97       196.33\n",
       "AB Tuned       0.99   0.99      0.99 0.99       831.61\n",
       "AB Trained     0.99   0.99      1.00 0.99        57.31"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check and compare results and Store performance metrics\n",
    "results = pd.DataFrame(index=[\"AB Base\", \"AB Tuned\", \"AB Trained\"], columns=[\"Accuracy\", \"Recall\", \"Precision\", \"F1\",\"Time(in sec)\"])\n",
    "results.iloc[0] = [0.94, 0.96, 0.97, 0.97, 196.33] # Results obtained from previous phase\n",
    "results.iloc[1] = [grid.cv_results_['mean_test_accuracy'][grid.best_index_],grid.cv_results_['mean_test_recall'][grid.best_index_], grid.cv_results_['mean_test_precision'][grid.best_index_], grid.cv_results_['mean_test_f1'][grid.best_index_],(end-start)]\n",
    "results.iloc[2] = [mean(accuracy_scores),mean(recall_scores),mean(precision_scores),mean(f1_scores),(end1-start1)]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f538cd-af8e-4c19-b308-01dfceaacf8b",
   "metadata": {},
   "source": [
    "### RESULT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d990ee-3e16-4014-a1d7-5b581ec36a34",
   "metadata": {},
   "source": [
    "- AB Base: This is likely the model with default hyperparameters. It has an accuracy of 0.94, recall of 0.96, precision of 0.97, F1 score of 0.97, and it took 196.33 seconds to run.\n",
    "- AB Tuned: This model probably had its hyperparameters tuned for better performance. It shows improvement across all metrics with an accuracy of 0.99, recall of 0.99, precision of 0.99, F1 score of 0.99, but it took significantly more time to run (831.61 seconds).\n",
    "- AB Trained: This model might have been further trained or fine-tuned on a specific dataset. It maintains high performance with an accuracy of 0.99, recall of 0.99, perfect precision of 1.00, F1 score of 0.99, and it’s the fastest with a runtime of 57.31 seconds.\n",
    "- These results indicate that tuning and training the AdaBoost model has led to significant improvements in model performance and efficiency. \n",
    "- The accuracy scores are quite high for both the training and testing sets.\n",
    "- Precision, Recall, and F1-score: All approximately 0.99 for both classes.\n",
    "- These results indicate that AB model is performing well on both the training and testing sets with a high degree of precision, recall, and F1-score. Hence no overfitting or underfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
