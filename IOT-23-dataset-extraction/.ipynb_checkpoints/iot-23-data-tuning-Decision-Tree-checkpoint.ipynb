{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da21591-6c8e-486f-ad05-5fb4b1d1f028",
   "metadata": {},
   "source": [
    "# Supervised ML methods for anomaly detection in IOT to enahnce network security\n",
    "## Part 4 - DATA TUNING - DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6226d3dc-dc98-4252-b452-51d2642c630a",
   "metadata": {},
   "source": [
    "The IoT-23 dataset is a collection of network traffic from Internet of Things (IoT) devices. It includes 20 malware captures executed in IoT devices, and 3 hotspot captures for benign IoT devices traffic12. The 3 hotspot captures are not being included in the data cleaning because this feature was not considered relevant for the specific analysis being performed.\n",
    "\n",
    "In this notebook, we load the processed dataset file and use it to tune one of the previously trained classification models.\n",
    "\n",
    "> **INPUT:** the cleaned and processed dataset csv file. <br>\n",
    "> **OUTPUT:** an analysis of the model's performance before/after tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee918b10-7a8c-46bd-be14-302474f7b611",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0d644b-ec0d-4566-86fd-eb22c1e8b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_score, confusion_matrix, recall_score, accuracy_score, f1_score\n",
    "from statistics import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fd39313-9539-4366-8919-8e41297fedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.float\", \"{:.2f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67eca1c8-a47e-48af-9a5d-ebcedd3c4551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "data_df = pd.read_csv('../CSV-data/processed/iot23_processed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c195875b-717b-4786-a618-faea566adf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into independent and dependent variables\n",
    "data_X = data_df.drop(\"label\", axis=1)\n",
    "data_y = data_df[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24abfaab-6fec-4cb3-b68b-89ff3c5e1370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform or normalize our data with standard scalar function\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74b3e256-e657-459b-bc04-df8f03d36150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d6ae4ca-5dbd-491f-8ca1-fc584ffdc787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0.0: 158360 samples\n",
      "Class 1.0: 158360 samples\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Define the oversampler and undersampler\n",
    "oversampler = RandomOverSampler(sampling_strategy='minority')\n",
    "undersampler = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "# Apply oversampling\n",
    "X_over, y_over = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Apply undersampling\n",
    "X_under, y_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "# Count the number of instances in each class\n",
    "counter = Counter(y_over)\n",
    "counter = Counter(y_under)\n",
    "\n",
    "# Print the number of instances in each class\n",
    "# the number of instances in the minority class should be equal to the number of instances in the majority class.\n",
    "for class_label, num_samples in counter.items():\n",
    "    print(f'Class {class_label}: {num_samples} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fee9b95-389e-4abe-b633-263007fe0eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X, data_y = make_classification(n_samples=158360, random_state=1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.2, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d4a569-b382-4a72-8deb-7e766d589012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best Parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'splitter': 'random'}\n",
      "time cost:  359.3211033344269 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Define the model\n",
    "model = DecisionTreeClassifier(random_state=1000)\n",
    "\n",
    "# Define the parameter grid\n",
    "parameters = {\"criterion\":(\"gini\", \"entropy\"), \n",
    "    \"splitter\":(\"best\", \"random\"), \n",
    "    'max_depth': [10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]}\n",
    "\n",
    "# Initialize cross validation method\n",
    "cross_validation_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1000)\n",
    "\n",
    "# Initialize tuning process\n",
    "grid = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=parameters, \n",
    "    scoring=['accuracy','recall','precision','f1'],\n",
    "    cv=cross_validation_folds,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit='accuracy')\n",
    "\n",
    "# Train the model\n",
    "grid.fit(data_X, data_y)\n",
    "best_params = grid.best_params_\n",
    "\n",
    "print (\"Best Parameters: {}\".format(grid.best_params_))\n",
    "\n",
    "end = time.time()\n",
    "print('time cost: ',end - start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6018eea2-d56c-410f-8626-74b4009265ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 99.47%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                 0        1  accuracy  macro avg  weighted avg\n",
      "precision     1.00     0.99      0.99       0.99          0.99\n",
      "recall        0.99     1.00      0.99       0.99          0.99\n",
      "f1-score      0.99     0.99      0.99       0.99          0.99\n",
      "support   63442.00 63246.00      0.99  126688.00     126688.00\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[63079   363]\n",
      " [  313 62933]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 99.49%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                 0        1  accuracy  macro avg  weighted avg\n",
      "precision     0.99     1.00      0.99       0.99          0.99\n",
      "recall        1.00     0.99      0.99       0.99          0.99\n",
      "f1-score      0.99     0.99      0.99       0.99          0.99\n",
      "support   15768.00 15904.00      0.99   31672.00      31672.00\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[15694    74]\n",
      " [   87 15817]]\n",
      "\n",
      "time cost:  0.4257781505584717 seconds\n"
     ]
    }
   ],
   "source": [
    "start1 = time.time()\n",
    "dt_clf = DecisionTreeClassifier(**best_params)\n",
    "\n",
    "# Initialize the results for each classifier\n",
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "precision_scores = []\n",
    "f1_scores = []\n",
    "best_f1 = -1\n",
    "best_model = None\n",
    "\n",
    "# Train the classifier\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test samples\n",
    "y_pred = dt_clf.predict(X_test)\n",
    "\n",
    "# Calculate and register accuracy metrics\n",
    "accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "recall_scores.append(recall_score(y_test, y_pred))\n",
    "precision_scores.append(precision_score(y_test, y_pred))\n",
    "est_f1_score = f1_score(y_test, y_pred)\n",
    "f1_scores.append(est_f1_score)\n",
    "\n",
    "# Compare with best performing model\n",
    "if best_f1 < est_f1_score:\n",
    "    best_model = dt_clf\n",
    "    best_f1 = est_f1_score\n",
    "\n",
    "print_score(dt_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(dt_clf, X_train, y_train, X_test, y_test, train=False)\n",
    "\n",
    "end1 = time.time()\n",
    "print('time cost: ',end1 - start1, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75d19653-55f6-4d23-aeab-ae388b1edfc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time(in sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DT Base</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>28.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT Tuned</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>359.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT Trained</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy Recall Precision   F1 Time(in sec)\n",
       "DT Base        0.97   0.98      0.98 0.98        28.03\n",
       "DT Tuned       0.99   0.99      0.99 0.99       359.32\n",
       "DT Trained     0.99   0.99      1.00 0.99         0.43"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check and compare results and Store performance metrics\n",
    "results = pd.DataFrame(index=[\"DT Base\", \"DT Tuned\", \"DT Trained\"], columns=[\"Accuracy\", \"Recall\", \"Precision\", \"F1\",\"Time(in sec)\"])\n",
    "results.iloc[0] = [0.97, 0.98, 0.98, 0.98, 28.03] # Results obtained from previous phase\n",
    "results.iloc[1] = [grid.cv_results_['mean_test_accuracy'][grid.best_index_],grid.cv_results_['mean_test_recall'][grid.best_index_], grid.cv_results_['mean_test_precision'][grid.best_index_], grid.cv_results_['mean_test_f1'][grid.best_index_],(end-start)]\n",
    "results.iloc[2] = [mean(accuracy_scores),mean(recall_scores),mean(precision_scores),mean(f1_scores),(end1-start1)]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f538cd-af8e-4c19-b308-01dfceaacf8b",
   "metadata": {},
   "source": [
    "### RESULT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d990ee-3e16-4014-a1d7-5b581ec36a34",
   "metadata": {},
   "source": [
    "- DT Base: This is likely the model with default hyperparameters. It has an accuracy of 0.97, recall of 0.98, precision of 0.98, F1 score of 0.98, and it took 28.03 seconds to run.\n",
    "- DT Tuned: This model probably had its hyperparameters tuned for better performance. It shows improvement across all metrics with an accuracy of 0.99, recall of 0.99, precision of 0.99, F1 score of 0.99, but it took significantly more time to run (359.32 seconds).\n",
    "- DT Trained: This model might have been further trained or fine-tuned on a specific dataset. It maintains high performance with an accuracy of 0.99, recall of 0.99, perfect precision of 1.00, F1 score of 0.99, and it’s the fastest with a runtime of 0.43 seconds.\n",
    "- These results indicate that tuning and training the Decision Tree model has led to significant improvements in model performance and efficiency. \n",
    "- The accuracy scores are quite high for both the training and testing sets.\n",
    "- Precision, Recall, and F1-score: All approximately 0.99 for both classes.\n",
    "- These results indicate that DT model is performing well on both the training and testing sets with a high degree of precision, recall, and F1-score. Hence no overfitting or underfitting.\n",
    "- An AUC value of 0.9948 indicates a method is better and almost perfect ranking. A higher AUC means the model is better at distinguishing between the classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
